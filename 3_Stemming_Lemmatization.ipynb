{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Basic definition of stemming is turn the word into the Verb 1. For example, if we have suffiex like \"-ed\" and \"-ing\", which may to cut off.\n",
    "\n",
    "There are three algorithms that can be used for stemming.\n",
    "1. Porter Stemmer\n",
    "2. Snowball Stemmer\n",
    "3. Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porter Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stemmer concern to removing the ending of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give: give\n",
      "giving: give\n",
      "given: given\n",
      "gave: gave\n"
     ]
    }
   ],
   "source": [
    "pst=PorterStemmer()\n",
    "words_to_stem=[\"give\",\"giving\",\"given\",\"gave\"]\n",
    "for words in words_to_stem:\n",
    "    print(words+ \": \" +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cook: cook\n",
      "cooking: cook\n",
      "cooked: cook\n",
      "cooks: cook\n"
     ]
    }
   ],
   "source": [
    "pst=PorterStemmer()\n",
    "words_to_stem=[\"cook\",\"cooking\",\"cooked\",\"cooks\"]\n",
    "for words in words_to_stem:\n",
    "    print(words+ \": \" +pst.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snowball Stemmer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also known as the Porter2 Stemming. It is accepted as better than Porter. And also more aggresive than Porter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cook: cook\n",
      "cooking: cook\n",
      "cooked: cook\n",
      "cooks: cook\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snw=SnowballStemmer(\"english\")\n",
    "words_to_stem=[\"cook\",\"cooking\",\"cooked\",\"cooks\"]\n",
    "for words in words_to_stem:\n",
    "    print(words+ \": \" +snw.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lancaster Stemmer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most aggresive stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cook: cook\n",
      "cooking: cook\n",
      "cooked: cook\n",
      "cooks: cook\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "lnc=LancasterStemmer()\n",
    "words_to_stem=[\"cook\",\"cooking\",\"cooked\",\"cooks\"]\n",
    "for words in words_to_stem:\n",
    "    print(words+ \": \" +lnc.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "Lemmatization is return an actual word of the language, it is used where it is necessary to get valid words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nndapsra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Library\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs: run\n",
      "running: running\n",
      "ran: ran\n"
     ]
    }
   ],
   "source": [
    "words_to_lemm=[\"runs\",\"running\",\"ran\"]\n",
    "word_lem=WordNetLemmatizer()\n",
    "\n",
    "for words in words_to_lemm:\n",
    "    print(words+ \": \" +word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cook: cook\n",
      "cooking: cooking\n",
      "be cooked: be cooked\n",
      "cooks: cook\n"
     ]
    }
   ],
   "source": [
    "words_to_lemm=[\"cook\",\"cooking\",\"be cooked\",\"cooks\"]\n",
    "word_lem=WordNetLemmatizer()\n",
    "\n",
    "for words in words_to_lemm:\n",
    "    print(words+ \": \" +word_lem.lemmatize(words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
